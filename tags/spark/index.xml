<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Namiking.net</title>
    <link>http://blog.namiking.net/tags/spark/</link>
    <description>Recent content in Spark on Namiking.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp-ja</language>
    <lastBuildDate>Tue, 12 Jan 2016 23:30:23 +0900</lastBuildDate>
    <atom:link href="http://blog.namiking.net/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Docker SwarmでApache Sparkクラスタを構築してみる</title>
      <link>http://blog.namiking.net/post/2016/01/docker-swarm-spark/</link>
      <pubDate>Tue, 12 Jan 2016 23:30:23 +0900</pubDate>
      
      <guid>http://blog.namiking.net/post/2016/01/docker-swarm-spark/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://blog.namiking.net/post/2016/01/docker-swarm-digitalocean/&#34;&gt;前回の記事&lt;/a&gt;でSwarmクラスタを構築したので、Apache Sparkのクラスタを載せてみる。&lt;/p&gt;

&lt;p&gt;本来ならオンプレでクラスタを組んだり、AmazonのEMRを使うのが一般的かもだが、安めのクラウドでもできないかなーという試み。&lt;/p&gt;

&lt;p&gt;まずはシンプルに、Standaloneモードから動かしてみたい。&lt;/p&gt;

&lt;h3 id=&#34;事前準備:27882acbebbf2525e531e2163851a874&#34;&gt;事前準備&lt;/h3&gt;

&lt;h4 id=&#34;マルチホスト同士の通信が可能なswarmクラスタを構築しておく:27882acbebbf2525e531e2163851a874&#34;&gt;マルチホスト同士の通信が可能なSwarmクラスタを構築しておく&lt;/h4&gt;

&lt;p&gt;Sparkのクラスタ同士は、一方通行な通信ではなく、割りと親密な双方向通信をするため、オーバーレイ・ネットワーク上に構築しないとうまく動作しない。&lt;/p&gt;

&lt;p&gt;オーバーレイ・ネットワーク構築するには、Consul, etcd, Zookeeperのようなキーストアを自身で導入する必要があるので、
&lt;a href=&#34;http://blog.namiking.net/post/2016/01/docker-swarm-digitalocean/&#34;&gt;DigitalOceanでマルチホストなDockerSwarmクラスタを構築&lt;/a&gt;を参考に、以下の様なSwarmクラスタを構築しておいた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/structure-swarm.svg&#34; alt=&#34;Swarm Structure&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;sparkクラスタをコンテナで構築する:27882acbebbf2525e531e2163851a874&#34;&gt;Sparkクラスタをコンテナで構築する&lt;/h3&gt;

&lt;p&gt;docker-composeを用いて、各ノードにSparkクラスタを構築する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-containers.svg&#34; alt=&#34;Spark Containers&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;apache-sparkのdockerイメージ:27882acbebbf2525e531e2163851a874&#34;&gt;Apache SparkのDockerイメージ&lt;/h4&gt;

&lt;p&gt;Standaloneモードで動くシンプルなものが使いたかったので、SparkのDockerイメージは自前で用意したものを使った。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;namikingsoft/docker-spark&lt;br /&gt;
&lt;a href=&#34;https://github.com/namikingsoft/docker-spark&#34;&gt;https://github.com/namikingsoft/docker-spark&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;masterなら&lt;code&gt;bin/start-master.sh&lt;/code&gt;を実行し、workerなら&lt;code&gt;bin/start-slave.sh ${MASTER_HOSTNAME}:7077&lt;/code&gt;を実行するだけのシンプルなもの。&lt;/p&gt;

&lt;h4 id=&#34;docker-compose-yml:27882acbebbf2525e531e2163851a874&#34;&gt;docker-compose.yml&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;master:
  image: namikingsoft/spark
  hostname: master
  container_name: master
  environment:
    - constraint:node==/node0/
  privileged: true
  command: master

worker:
  image: namikingsoft/spark
  environment:
    - MASTER_HOSTNAME=master
    - constraint:node!=/node0/
    - affinity:container!=/worker/
  privileged: true
  command: worker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;environment&lt;/code&gt;からの&lt;code&gt;constraint&lt;/code&gt;や&lt;code&gt;affinity&lt;/code&gt;の指定によってコンテナの配置をコントロールできる。コンテナの数をスケールするときもこのルールに沿って配置される。&lt;br /&gt;
&lt;a href=&#34;https://docs.docker.com/swarm/scheduler/filter/&#34;&gt;&amp;gt;&amp;gt; 指定方法の詳細&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;イメージ各コンテナはDockerのオーバーレイネットワークで繋がるので、
ポートも特に指定しなくてもよい。WebUIなどは後ほど、Socksプロキシ経由で確認する。&lt;/p&gt;

&lt;h4 id=&#34;swarm-masterの環境変数を設定:27882acbebbf2525e531e2163851a874&#34;&gt;Swarm Masterの環境変数を設定&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;eval &amp;quot;$(docker-machine env --swarm swarm-node0)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;docker-compose-up:27882acbebbf2525e531e2163851a874&#34;&gt;docker-compose up&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose --x-networking up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--x-networking&lt;/code&gt;を引数で指定すれば、各コンテナがDockerのオーバーレイ・ネットワークで繋がる。&lt;code&gt;--x-network-driver overlay&lt;/code&gt;を省略しているが、デフォルトで指定されるみたい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker-compose up&lt;/code&gt;直後の状態では、ワーカーコンテナが１つしか立ち上がらないので、以下の様な感じになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-containers-progress.svg&#34; alt=&#34;Spark Containers Progress&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;ワーカーをスケールしてみる:27882acbebbf2525e531e2163851a874&#34;&gt;ワーカーをスケールしてみる&lt;/h4&gt;

&lt;p&gt;docker-composeのscaleコマンドでワーカーノードを指定数分スケールすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose scale worker=2
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;コンテナ配置の確認:27882acbebbf2525e531e2163851a874&#34;&gt;コンテナ配置の確認&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker ps --format &amp;quot;{{.Names}}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;swarm-node0/master
swarm-node1/dockerspark_worker_1
swarm-node2/dockerspark_worker_2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;各ノードにコンテナが配置されたのがわかる。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ちなみに、MasterとWorkerを一緒のノードで動かしたら&lt;/strong&gt;&lt;br /&gt;
spark-shell起動時に&lt;code&gt;Cannot allocate memory&lt;/code&gt;的なエラーを吐いた。
チューニング次第かもだが、DigitalOcean 2GBだとリソース的には厳しそう。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;sparkシェルを動かしてみる:27882acbebbf2525e531e2163851a874&#34;&gt;Sparkシェルを動かしてみる&lt;/h3&gt;

&lt;p&gt;仮にSparkマスターコンテナをドライバーとして、動かしてみる。
(ワーカーでも動作可能)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-exec -it master bash
spark-shell --master spark://master:7077
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;scala&amp;gt; sc.parallelize(1 to 10000).fold(0)(_+_)
res0: Int = 50005000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;spark-uiを確認:27882acbebbf2525e531e2163851a874&#34;&gt;Spark UIを確認&lt;/h3&gt;

&lt;p&gt;SparkのWebUIから、ワーカーが接続されているか確認したいが、docker-compose.ymlではポートを開けていない。(本来閉じたネットワークで動かすので、ポートを開放するのはあまりよろしくない)&lt;/p&gt;

&lt;p&gt;なので、新たにSSHdコンテナを設置して、Socksプロキシ経由でWebUIを確認する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-sshsocks.svg&#34; alt=&#34;Sparkマスター WebUI&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;sshdコンテナを追加:27882acbebbf2525e531e2163851a874&#34;&gt;SSHdコンテナを追加&lt;/h4&gt;

&lt;p&gt;先ほどのdocker-compose.ymlに追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;master:
  image: namikingsoft/spark
  hostname: master
  container_name: master
  environment:
    - constraint:node==/node0/
  privileged: true
  command: master

worker:
  image: namikingsoft/spark
  hostname: woker
  environment:
    - constraint:node!=/node0/
    - affinity:container!=/worker/
  privileged: true
  command: worker

# SSHdコンテナを追加
sshd:
  image: fedora/ssh
  ports:
    - &amp;quot;2222:22&amp;quot;
  environment:
    SSH_USERNAME: user
    SSH_USERPASS: something
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のコマンドで、SSHdコンテナが起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose --x-networking up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;ローカルpcでsocksプロキシを起動:27882acbebbf2525e531e2163851a874&#34;&gt;ローカルPCでSocksプロキシを起動&lt;/h4&gt;

&lt;p&gt;swarm-masterのIPを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-machine ls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Socksプロキシの起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ssh user@(swarm-masterのIP) -p2222 -D1080 -fN
Password: something
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Socksプロキシを止めるときは&lt;code&gt;Ctrl-c&lt;/code&gt;を押下。&lt;/p&gt;

&lt;h4 id=&#34;ローカルpcにてsocksプロキシを設定:27882acbebbf2525e531e2163851a874&#34;&gt;ローカルPCにてSocksプロキシを設定&lt;/h4&gt;

&lt;p&gt;ローカルPCのSocksプロキシ設定を&lt;code&gt;localhost:1080&lt;/code&gt;に設定する。
SSHのSocks周りについては以下のページが参考になった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.wktk.co.jp/ja/entry/2014/03/11/ssh-socks-proxy-mac-chrome&#34;&gt;ssh経由のSOCKSプロキシを通じてMac上のGoogle Chromeでブラウジング&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kmc.gr.jp/advent-calendar/ssh/2013/12/14/tsocks.html&#34;&gt;ssh -D と tsocks -  京大マイコンクラブ (KMC)&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;ブラウザで確認:27882acbebbf2525e531e2163851a874&#34;&gt;ブラウザで確認&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;open http://(swarm-masterのIP):8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-master-ui.png&#34; alt=&#34;Sparkマスター WebUI&#34; /&gt;&lt;/p&gt;

&lt;p&gt;先ほど、スケールした2つのワーカーコンテナがマスターに接続されているのがわかる。
IPや名前解決はSSH接続先のものを参照してくれて便利。(OSX10.9+Chromeで確認)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-worker-ui.png&#34; alt=&#34;Sparkワーカー WebUI&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>