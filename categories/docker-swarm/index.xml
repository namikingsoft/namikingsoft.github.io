<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker Swarm on Namiking.net</title>
    <link>http://blog.namiking.net/categories/docker-swarm/</link>
    <description>Recent content in Docker Swarm on Namiking.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>jp-ja</language>
    <lastBuildDate>Mon, 18 Jan 2016 20:00:00 +0900</lastBuildDate>
    <atom:link href="http://blog.namiking.net/categories/docker-swarm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>TLS認証なDocker Swarmクラスタを構築 (docker-machineなしで)</title>
      <link>http://blog.namiking.net/post/2016/01/docker-swarm-build-using-tls/</link>
      <pubDate>Mon, 18 Jan 2016 20:00:00 +0900</pubDate>
      
      <guid>http://blog.namiking.net/post/2016/01/docker-swarm-build-using-tls/</guid>
      <description>

&lt;p&gt;TSL認証なSwarmクラスタはdocker-machineで構築すると、勝手に設定してくれて非常に楽だが、ホストのネットワークを事前に弄りたかったり、Terraformなどの他オーケストレーションツールを組み合わせたいときに、ちょっと融通がきかない。&lt;/p&gt;

&lt;p&gt;なので、TSL認証を用いたDocker Swarmクラスタを&lt;strong&gt;自力で&lt;/strong&gt;構築できるように、手順をまとめておきたい。また、docker-machineの代替として&lt;strong&gt;Terraform&lt;/strong&gt;を使い、自動化できるようにしたい。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-build-using-tls/eyecatch.png&#34; alt=&#34;Docker Swarm using TLS&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;作業の流れ:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;作業の流れ&lt;/h3&gt;

&lt;p&gt;概ね以下の様な流れでSwarmクラスタの構築を行う。基本的には、docker-machineで行われていることを模倣している。docker-machine自体ではサービスディスカバリの準備は行わないので、そこら辺の手順も残しておく。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-build-using-tls/overview.svg&#34; alt=&#34;Overview&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;付録-swarmクラスタをterraformで構築するサンプル:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;[付録] SwarmクラスタをTerraformで構築するサンプル&lt;/h4&gt;

&lt;p&gt;今回の記事で行う作業をTerraformで自動化したものを、以下のリポジトリに置いておくので、ご参考までに。terraform.tfの&lt;code&gt;count&lt;/code&gt;の値を弄ることで、指定数のノードを自動で作成するので、大量にノードが必要な場合に便利かも。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;GitHub: namikingsoft/sample-terraform-docker-swarm
&lt;a href=&#34;https://github.com/namikingsoft/sample-terraform-docker-swarm&#34;&gt;https://github.com/namikingsoft/sample-terraform-docker-swarm&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;事前準備:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;事前準備&lt;/h3&gt;

&lt;h4 id=&#34;必要なソフトウェアのインストール:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;必要なソフトウェアのインストール&lt;/h4&gt;

&lt;p&gt;作業で使うPC(またはホスト)に以下のDocker関連のソフトウェアをインストールしておく。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;docker (Engine)&lt;/li&gt;
&lt;li&gt;OpenSSL (Linux系やOSXなら、デフォルトで入っているはず)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;digitaloceanの登録とアクセストークンの取得:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;DigitalOceanの登録とアクセストークンの取得&lt;/h4&gt;

&lt;p&gt;この記事の例では、ホストにDigitalOceanを使うが、AWSとかでも可能と思います。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;https://www.digitalocean.com/&lt;/a&gt;&lt;br /&gt;
登録後、管理画面からdocker-machineとの連携に必要なアクセストークンを発行できる。&lt;/p&gt;

&lt;h3 id=&#34;ノード用のホストを用意する:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;ノード用のホストを用意する&lt;/h3&gt;

&lt;p&gt;今回の例では、DigitalOceanでノードを２台用意して、Swarmクラスタの連携を確認した。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Host&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;OS&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Mem&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;IP (eth0)&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;IP (eth1)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;swarm-node0&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ubuntu-15-10-x64&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;512MB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;x.x.x.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;y.y.y.1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;swarm-node1&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;ubuntu-15-10-x64&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;512MB&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;x.x.x.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;y.y.y.2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&#34;備考:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;備考&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;swarm-node0はマスターノードとして使う&lt;/li&gt;
&lt;li&gt;ホスト名(hostname)は別になんでもよい&lt;/li&gt;
&lt;li&gt;プライベートネットワークを有効にしておく&lt;/li&gt;
&lt;li&gt;eth0はグローバルネットワークに繋がるインタフェース&lt;/li&gt;
&lt;li&gt;eth1はプライベートネットワークに繋がるインタフェース&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;各ノードでconsulを動かす:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;各ノードでConsulを動かす&lt;/h3&gt;

&lt;p&gt;Swarmクラスタのサービスディスカバリー(分散KVS)であるConsulを各ノードにインストールする。使わないでもSwarmクラスタは構築できるが、マルチホスト間でオーバーレイ・ネットワークを作れるようになったりと色々利点が多いので。(etcdやZookeeperでも構築可能)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-build-using-tls/consul.svg&#34; alt=&#34;Swarm Structure&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;swarm-node0にてconsulをサーバーモードで動かす:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node0にてConsulをサーバーモードで動かす&lt;/h4&gt;

&lt;p&gt;SSHでログインして作業を行う。&lt;/p&gt;

&lt;h5 id=&#34;consulインストール:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Consulインストール&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# 必要なパッケージのインストール
apt-get install -y curl zip

# Consulインストール
cd /tmp
curl -LO https://releases.hashicorp.com/consul/0.6.1/consul_0.6.1_linux_amd64.zip
unzip consul_0.6.1_linux_amd64.zip
mv consul /usr/local/bin

# ConsulのWebUIを設置(任意)
curl -LO https://releases.hashicorp.com/consul/0.6.1/consul_0.6.1_web_ui.zip
unzip consul_0.6.1_web_ui.zip -d consul-webui
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;consul起動:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Consul起動&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;nohup consul agent \
  -server -bootstrap-expect=1 \
  -node=consul0 \
  -data-dir=/tmp/consul \
  --ui-dir=/tmp/consul-webui \
  -bind=$(
    ip addr show eth1 \
    | grep -o -e &#39;[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+&#39; \
    | head -n1
  ) \
  &amp;gt;&amp;gt; /var/log/consul.log &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;１台構成のサーバーモードをWebUI付き(任意)で起動する。プライベートネットワークであるeth1のIPにバインドする。&lt;/p&gt;

&lt;h4 id=&#34;swarm-node1にてconsulをクライアントモードで動かす:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node1にてConsulをクライアントモードで動かす&lt;/h4&gt;

&lt;p&gt;SSHでログインして作業を行う。インストール方法は同じなので割愛。&lt;/p&gt;

&lt;h5 id=&#34;consul起動-1:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Consul起動&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;nohup consul agent \
  -join y.y.y.1 \
  -node=consul1 \
  -data-dir=/tmp/consul \
  --ui-dir=/tmp/consul-webui \
  -bind=$(
    ip addr show eth1 \
    | grep -o -e &#39;[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+&#39; \
    | head -n1
  ) \
  &amp;gt;&amp;gt; /var/log/consul.log &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;swarm-node0のプライベートIPにジョインする。&lt;/p&gt;

&lt;h4 id=&#34;メンバー確認:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;メンバー確認&lt;/h4&gt;

&lt;p&gt;各ノードのConsulが連携できているかを確認する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ consul members

Node     Address            Status  Type    Build  Protocol  DC
consul0  y.y.y.1:8301   alive   server  0.6.1  2         dc1
consul1  y.y.y.2:8301   alive   client  0.6.1  2         dc1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;各ノードにdockerをインストール:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;各ノードにDockerをインストール&lt;/h3&gt;

&lt;p&gt;各ノードのSSHにて、以下のコマンドを実行する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget -qO- https://get.docker.com/ | sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;デーモン起動時の引数設定などは後ほど行う。&lt;/p&gt;

&lt;h3 id=&#34;tls認証用の鍵を生成する:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;TLS認証用の鍵を生成する&lt;/h3&gt;

&lt;p&gt;クライアント側(ローカルPC)で生成する。後ほど各ノードに必要なファイルを転送する。&lt;/p&gt;

&lt;h4 id=&#34;caの証明書を生成:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;CAの証明書を生成&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;openssl genrsa -out ca-key.pem 4096
openssl req -subj &amp;quot;/CN=ca&amp;quot; -new -x509 -days 365 -key ca-key.pem -out ca.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;クライアントの秘密鍵と証明書を生成:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;クライアントの秘密鍵と証明書を生成&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# extfile
echo &amp;quot;extendedKeyUsage = clientAuth&amp;quot; &amp;gt;&amp;gt; extfile-client.cnf

# client cert
openssl genrsa -out key.pem 4096
openssl req -subj &#39;/CN=client&#39; -new -key key.pem -out client.csr
openssl x509 -req -days 365 -sha256 -in client.csr -out cert.pem \
  -CA ca.pem -CAkey ca-key.pem -CAcreateserial -extfile extfile-client.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;swarm-node0-master-の秘密鍵と証明書を生成:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node0(master)の秘密鍵と証明書を生成&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# extfile
echo &amp;quot;subjectAltName = IP:x.x.x.1&amp;quot; &amp;gt; extfile.cnf
echo &amp;quot;extendedKeyUsage = clientAuth,serverAuth&amp;quot; &amp;gt;&amp;gt; extfile.cnf

# server cert
openssl genrsa -out node0-key.pem 4096
openssl req -subj &amp;quot;/CN=node0&amp;quot; -new -key node0-key.pem -out node0.csr
openssl x509 -req -days 365 -sha256 -in node0.csr -out node0-cert.pem \
  -CA ca.pem -CAkey ca-key.pem -CAcreateserial -extfile extfile.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Swarm Managerを動かすノードなので、clientAuthも設定しておく。subjectAltNameにグローバルIPを設定するので、CommonName(CN)は割と何でもよいが、ドメイン名があれば、それを設定するとよい。&lt;/p&gt;

&lt;h4 id=&#34;swarm-node1の秘密鍵と証明書を生成:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node1の秘密鍵と証明書を生成&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# extfile
echo &amp;quot;subjectAltName = IP:x.x.x.2&amp;quot; &amp;gt; extfile.cnf

# server cert
openssl genrsa -out node1-key.pem 4096
openssl req -subj &amp;quot;/CN=node1&amp;quot; -new -key node1-key.pem -out node1.csr
openssl x509 -req -days 365 -sha256 -in node1.csr -out node1-cert.pem \
  -CA ca.pem -CAkey ca-key.pem -CAcreateserial -extfile extfile.cnf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CommonName(CN)は任意。&lt;/p&gt;

&lt;h4 id=&#34;tls認証鍵を各ノードへアップロード:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;TLS認証鍵を各ノードへアップロード&lt;/h4&gt;

&lt;p&gt;SFTPやSCPなどを使って、各ノードの&lt;code&gt;/etc/docker&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:357fa4bd2e644c21db7997b0a9ea5cf8:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:357fa4bd2e644c21db7997b0a9ea5cf8:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;あたりにアップロードする。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;swarm-node0

&lt;ul&gt;
&lt;li&gt;ca.pem&lt;/li&gt;
&lt;li&gt;node0-cert.pem&lt;/li&gt;
&lt;li&gt;node0-key.pem&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;swarm-node1

&lt;ul&gt;
&lt;li&gt;ca.pem&lt;/li&gt;
&lt;li&gt;node1-cert.pem&lt;/li&gt;
&lt;li&gt;node1-key.pem&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;各ノードのdockerの設定を変更する:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;各ノードのDockerの設定を変更する&lt;/h3&gt;

&lt;p&gt;各ノードにSSHでログインして、設定を行う。&lt;/p&gt;

&lt;h4 id=&#34;dockerデーモン起動時の引数設定:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Dockerデーモン起動時の引数設定&lt;/h4&gt;

&lt;h5 id=&#34;swarm-node0:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node0&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;vi /lib/systemd/system/docker.service

# 変更前
ExecStart=/usr/bin/docker daemon -H fd://
# 変更後
ExecStart=/usr/bin/docker daemon \
  --tlsverify \
  --tlscacert=/etc/docker/ca.pem \
  --tlscert=/etc/docker/node0-cert.pem \
  --tlskey=/etc/docker/node0-key.pem \
  -H=0.0.0.0:2376a\
  --cluster-store=consul://localhost:8500 \
  --cluster-advertise=eth0:2376 \
  -H fd://
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;swarm-node1:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node1&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;vi /lib/systemd/system/docker.service

# 変更前
ExecStart=/usr/bin/docker daemon -H fd://
# 変更後
ExecStart=/usr/bin/docker daemon \
  --tlsverify \
  --tlscacert=/etc/docker/ca.pem \
  --tlscert=/etc/docker/node1-cert.pem \
  --tlskey=/etc/docker/node1-key.pem \
  -H=0.0.0.0:2376 \
  --cluster-store=consul://localhost:8500 \
  --cluster-advertise=eth0:2376 \
  -H fd://
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;備考-1:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;備考&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;変更後は見やすさのため複数行で書いているが、&lt;code&gt;\&lt;/code&gt;を消して1行ぶっ続けで記述する。&lt;/li&gt;
&lt;li&gt;この設定はUbuntu15.10の場合なので、他のOSの場合は&lt;code&gt;/etc/default/docker&lt;/code&gt;の&lt;code&gt;DOCKER_OPTS&lt;/code&gt;に引数を付け加えたりなど、やり方が違ってくると思うので、各々調節する。&lt;/li&gt;
&lt;li&gt;cluster-storeとcluster-advertiseの指定は、オーバーレイ・ネットワーク機能のためなので、使わない場合は特に指定しなくても、Swarmクラスタの動作は可能。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;docker再起動:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Docker再起動&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;service docker restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;tls接続確認:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;TLS接続確認&lt;/h4&gt;

&lt;p&gt;ローカルPCから、TLS(TCP)でホストのDockerを利用できるか確認してみる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# swarm-node0
docker --tlsverify \
  --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem \
  -H=x.x.x.1:2376 \
  version

# swarm-node1
docker --tlsverify \
  --tlscacert=ca.pem --tlscert=cert.pem --tlskey=key.pem \
  -H=x.x.x.2:2376 \
  version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ClientとServerのDockerバージョンが表示されれば、正しく設定できている。&lt;/p&gt;

&lt;p&gt;また、以下の様な環境変数を設定することで、いちいちTLS認証鍵やIP指定をしなくても、普通にdockerコマンドが扱えるようになる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://(dockerホストのIP):2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/path/to/クライアント認証鍵があるディレクトリ&amp;quot;

docker version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;DOCKER_CERT_PATH&lt;/code&gt;については、&lt;code&gt;~/.docker/&lt;/code&gt;にクライアント認証鍵(ca.pem, cert.pem, key.pem)を設置すれば、省略可能。&lt;/p&gt;

&lt;h3 id=&#34;各ノードでswarmコンテナを動かす:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;各ノードでSwarmコンテナを動かす&lt;/h3&gt;

&lt;p&gt;各ノードにSSHでログインして、Swarmコンテナを起動させる。&lt;/p&gt;

&lt;h4 id=&#34;swarm-node0-1:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node0&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Swarm Manager
docker run -d --name swarm-agent-master \
  -v /etc/docker:/etc/docker --net host \
  swarm manage --tlsverify \
    --tlscacert=/etc/docker/ca.pem \
    --tlscert=/etc/docker/server-cert.pem \
    --tlskey=/etc/docker/server-key.pem \
    -H tcp://0.0.0.0:3376 --strategy spread \
    --advertise x.x.x.1:2376 consul://localhost:8500

# Swarm Agent
docker run -d --name swarm-agent --net host \
  swarm join --advertise x.x.x.1:2376 consul://localhost:8500
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;swarm-node1-1:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;swarm-node1&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# Swarm Agent
docker run -d --name swarm-agent --net host \
  swarm join --advertise x.x.x.2:2376 consul://localhost:8500
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;備考-2:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;備考&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;ネットワークのホストと共有する必要があるので、&lt;code&gt;--net host&lt;/code&gt;を指定している。&lt;/li&gt;
&lt;li&gt;Swarm Managerで&lt;code&gt;/etc/docker&lt;/code&gt;を共有Volume指定しているのは、TLS認証鍵の共有だけではなく、&lt;code&gt;/etc/docker/key.json&lt;/code&gt;の共有のため。DockerユニークIDの識別に必要とのこと。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;動作確認:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;動作確認&lt;/h3&gt;

&lt;p&gt;クライアント側(ローカルPC)から、Swarmクラスタへの接続を試みる。&lt;/p&gt;

&lt;h4 id=&#34;swarm-masterにtls接続:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Swarm MasterにTLS接続&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://x.x.x.1:3376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/path/to/クライアント認証鍵があるディレクトリ&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker info

Containers: 3
Images: 2
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 2
 swarm-node0: x.x.x.1:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 513.4 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.2.0-16-generic, operatingsystem=Ubuntu 15.10, storagedriver=aufs
 swarm-node1: x.x.x.2:2376
  └ Status: Healthy
  └ Containers: 1
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 513.4 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.2.0-16-generic, operatingsystem=Ubuntu 15.10, storagedriver=aufs
CPUs: 2
Total Memory: 1.003 GiB
Name: swarm-node0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上のように、ノードが2つ接続されていることが確認できれば、Swarmクラスタの構築がうまく行えている。&lt;code&gt;DOCKER_HOST&lt;/code&gt;のポート指定を&lt;code&gt;2376&lt;/code&gt;ではなく、&lt;code&gt;3376&lt;/code&gt;にすることで、dockerコマンドでSwarm関連の操作を行うことができる。&lt;/p&gt;

&lt;h4 id=&#34;swarmクラスタにコンテナを配置してみる:357fa4bd2e644c21db7997b0a9ea5cf8&#34;&gt;Swarmクラスタにコンテナを配置してみる&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker run -d --name container1 nginx
$ docker run -d --name container2 nginx
$ docker ps --format &amp;quot;{{.Names}}&amp;quot;

swarm-node1/container1
swarm-node2/container2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Swarm Masterのストラテジーが&lt;code&gt;spread&lt;/code&gt;なので、各ノードにコンテナが分散配置される。&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:357fa4bd2e644c21db7997b0a9ea5cf8:1&#34;&gt;TLS認証鍵の置き場所は任意。Dockerデーモン起動時の引数で指定する。
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:357fa4bd2e644c21db7997b0a9ea5cf8:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Docker SwarmでApache Sparkクラスタを構築してみる</title>
      <link>http://blog.namiking.net/post/2016/01/docker-swarm-spark/</link>
      <pubDate>Tue, 12 Jan 2016 23:30:23 +0900</pubDate>
      
      <guid>http://blog.namiking.net/post/2016/01/docker-swarm-spark/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://blog.namiking.net/post/2016/01/docker-swarm-digitalocean/&#34;&gt;前回の記事&lt;/a&gt;でSwarmクラスタを構築したので、Apache Sparkのクラスタを載せてみる。&lt;/p&gt;

&lt;p&gt;本来ならオンプレでクラスタを組んだり、AmazonのEMRを使うのが一般的かもだが、安めのクラウドでもできないかなーという試み。&lt;/p&gt;

&lt;p&gt;まずはシンプルに、Standaloneモードから動かしてみたい。&lt;/p&gt;

&lt;h3 id=&#34;事前準備:27882acbebbf2525e531e2163851a874&#34;&gt;事前準備&lt;/h3&gt;

&lt;h4 id=&#34;マルチホスト同士の通信が可能なswarmクラスタを構築しておく:27882acbebbf2525e531e2163851a874&#34;&gt;マルチホスト同士の通信が可能なSwarmクラスタを構築しておく&lt;/h4&gt;

&lt;p&gt;Sparkのクラスタ同士は、一方通行な通信ではなく、割りと親密な双方向通信をするため、オーバーレイ・ネットワーク上に構築しないとうまく動作しない。&lt;/p&gt;

&lt;p&gt;オーバーレイ・ネットワーク構築するには、Consul, etcd, Zookeeperのようなキーストアを自身で導入する必要があるので、
&lt;a href=&#34;http://blog.namiking.net/post/2016/01/docker-swarm-digitalocean/&#34;&gt;DigitalOceanでマルチホストなDockerSwarmクラスタを構築&lt;/a&gt;を参考に、以下の様なSwarmクラスタを構築しておいた。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/structure-swarm.svg&#34; alt=&#34;Swarm Structure&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;sparkクラスタをコンテナで構築する:27882acbebbf2525e531e2163851a874&#34;&gt;Sparkクラスタをコンテナで構築する&lt;/h3&gt;

&lt;p&gt;docker-composeを用いて、各ノードにSparkクラスタを構築する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-containers.svg&#34; alt=&#34;Spark Containers&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;apache-sparkのdockerイメージ:27882acbebbf2525e531e2163851a874&#34;&gt;Apache SparkのDockerイメージ&lt;/h4&gt;

&lt;p&gt;Standaloneモードで動くシンプルなものが使いたかったので、SparkのDockerイメージは自前で用意したものを使った。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;namikingsoft/docker-spark&lt;br /&gt;
&lt;a href=&#34;https://github.com/namikingsoft/docker-spark&#34;&gt;https://github.com/namikingsoft/docker-spark&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;masterなら&lt;code&gt;bin/start-master.sh&lt;/code&gt;を実行し、workerなら&lt;code&gt;bin/start-slave.sh ${MASTER_HOSTNAME}:7077&lt;/code&gt;を実行するだけのシンプルなもの。&lt;/p&gt;

&lt;h4 id=&#34;docker-compose-yml:27882acbebbf2525e531e2163851a874&#34;&gt;docker-compose.yml&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;master:
  image: namikingsoft/spark
  hostname: master
  container_name: master
  environment:
    - constraint:node==/node0/
  privileged: true
  command: master

worker:
  image: namikingsoft/spark
  environment:
    - MASTER_HOSTNAME=master
    - constraint:node!=/node0/
    - affinity:container!=/worker/
  privileged: true
  command: worker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;environment&lt;/code&gt;からの&lt;code&gt;constraint&lt;/code&gt;や&lt;code&gt;affinity&lt;/code&gt;の指定によってコンテナの配置をコントロールできる。コンテナの数をスケールするときもこのルールに沿って配置される。&lt;br /&gt;
&lt;a href=&#34;https://docs.docker.com/swarm/scheduler/filter/&#34;&gt;&amp;gt;&amp;gt; 指定方法の詳細&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;イメージ各コンテナはDockerのオーバーレイネットワークで繋がるので、
ポートも特に指定しなくてもよい。WebUIなどは後ほど、Socksプロキシ経由で確認する。&lt;/p&gt;

&lt;h4 id=&#34;swarm-masterの環境変数を設定:27882acbebbf2525e531e2163851a874&#34;&gt;Swarm Masterの環境変数を設定&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;eval &amp;quot;$(docker-machine env --swarm swarm-node0)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;docker-compose-up:27882acbebbf2525e531e2163851a874&#34;&gt;docker-compose up&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose --x-networking up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;--x-networking&lt;/code&gt;を引数で指定すれば、各コンテナがDockerのオーバーレイ・ネットワークで繋がる。&lt;code&gt;--x-network-driver overlay&lt;/code&gt;を省略しているが、デフォルトで指定されるみたい。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker-compose up&lt;/code&gt;直後の状態では、ワーカーコンテナが１つしか立ち上がらないので、以下の様な感じになっている。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-containers-progress.svg&#34; alt=&#34;Spark Containers Progress&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;ワーカーをスケールしてみる:27882acbebbf2525e531e2163851a874&#34;&gt;ワーカーをスケールしてみる&lt;/h4&gt;

&lt;p&gt;docker-composeのscaleコマンドでワーカーノードを指定数分スケールすることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose scale worker=2
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;コンテナ配置の確認:27882acbebbf2525e531e2163851a874&#34;&gt;コンテナ配置の確認&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker ps --format &amp;quot;{{.Names}}&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;swarm-node0/master
swarm-node1/dockerspark_worker_1
swarm-node2/dockerspark_worker_2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;各ノードにコンテナが配置されたのがわかる。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ちなみに、MasterとWorkerを一緒のノードで動かしたら&lt;/strong&gt;&lt;br /&gt;
spark-shell起動時に&lt;code&gt;Cannot allocate memory&lt;/code&gt;的なエラーを吐いた。
チューニング次第かもだが、DigitalOcean 2GBだとリソース的には厳しそう。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;sparkシェルを動かしてみる:27882acbebbf2525e531e2163851a874&#34;&gt;Sparkシェルを動かしてみる&lt;/h3&gt;

&lt;p&gt;仮にSparkマスターコンテナをドライバーとして、動かしてみる。
(ワーカーでも動作可能)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-exec -it master bash
spark-shell --master spark://master:7077
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;scala&amp;gt; sc.parallelize(1 to 10000).fold(0)(_+_)
res0: Int = 50005000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;spark-uiを確認:27882acbebbf2525e531e2163851a874&#34;&gt;Spark UIを確認&lt;/h3&gt;

&lt;p&gt;SparkのWebUIから、ワーカーが接続されているか確認したいが、docker-compose.ymlではポートを開けていない。(本来閉じたネットワークで動かすので、ポートを開放するのはあまりよろしくない)&lt;/p&gt;

&lt;p&gt;なので、新たにSSHdコンテナを設置して、Socksプロキシ経由でWebUIを確認する。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-sshsocks.svg&#34; alt=&#34;Sparkマスター WebUI&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;sshdコンテナを追加:27882acbebbf2525e531e2163851a874&#34;&gt;SSHdコンテナを追加&lt;/h4&gt;

&lt;p&gt;先ほどのdocker-compose.ymlに追加する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;master:
  image: namikingsoft/spark
  hostname: master
  container_name: master
  environment:
    - constraint:node==/node0/
  privileged: true
  command: master

worker:
  image: namikingsoft/spark
  hostname: woker
  environment:
    - constraint:node!=/node0/
    - affinity:container!=/worker/
  privileged: true
  command: worker

# SSHdコンテナを追加
sshd:
  image: fedora/ssh
  ports:
    - &amp;quot;2222:22&amp;quot;
  environment:
    SSH_USERNAME: user
    SSH_USERPASS: something
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以下のコマンドで、SSHdコンテナが起動する。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-compose --x-networking up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;ローカルpcでsocksプロキシを起動:27882acbebbf2525e531e2163851a874&#34;&gt;ローカルPCでSocksプロキシを起動&lt;/h4&gt;

&lt;p&gt;swarm-masterのIPを確認。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-machine ls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Socksプロキシの起動。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ssh user@(swarm-masterのIP) -p2222 -D1080 -fN
Password: something
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Socksプロキシを止めるときは&lt;code&gt;Ctrl-c&lt;/code&gt;を押下。&lt;/p&gt;

&lt;h4 id=&#34;ローカルpcにてsocksプロキシを設定:27882acbebbf2525e531e2163851a874&#34;&gt;ローカルPCにてSocksプロキシを設定&lt;/h4&gt;

&lt;p&gt;ローカルPCのSocksプロキシ設定を&lt;code&gt;localhost:1080&lt;/code&gt;に設定する。
SSHのSocks周りについては以下のページが参考になった。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.wktk.co.jp/ja/entry/2014/03/11/ssh-socks-proxy-mac-chrome&#34;&gt;ssh経由のSOCKSプロキシを通じてMac上のGoogle Chromeでブラウジング&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.kmc.gr.jp/advent-calendar/ssh/2013/12/14/tsocks.html&#34;&gt;ssh -D と tsocks -  京大マイコンクラブ (KMC)&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;ブラウザで確認:27882acbebbf2525e531e2163851a874&#34;&gt;ブラウザで確認&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;open http://(swarm-masterのIP):8080
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-master-ui.png&#34; alt=&#34;Sparkマスター WebUI&#34; /&gt;&lt;/p&gt;

&lt;p&gt;先ほど、スケールした2つのワーカーコンテナがマスターに接続されているのがわかる。
IPや名前解決はSSH接続先のものを参照してくれて便利。(OSX10.9+Chromeで確認)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-spark/spark-worker-ui.png&#34; alt=&#34;Sparkワーカー WebUI&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DigitalOceanでマルチホストなDockerSwarmクラスタを構築するときのポイント</title>
      <link>http://blog.namiking.net/post/2016/01/docker-swarm-digitalocean/</link>
      <pubDate>Sun, 10 Jan 2016 18:00:23 +0900</pubDate>
      
      <guid>http://blog.namiking.net/post/2016/01/docker-swarm-digitalocean/</guid>
      <description>

&lt;p&gt;Docker公式の&lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/get-started-overlay/&#34;&gt;Get started with multi-host networking&lt;/a&gt;を参考に、DigitalOceanでSwarmクラスタを構築してみたが、いくつか工夫が必要なポイントがあったので、まとめておく。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-digitalocean/logos.png&#34; alt=&#34;Docker Swarm + DigitalOcean&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;事前準備:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;事前準備&lt;/h3&gt;

&lt;h4 id=&#34;必要なソフトウェアのインストール:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;必要なソフトウェアのインストール&lt;/h4&gt;

&lt;p&gt;作業で使うPC(またはホスト)に以下のDocker関連のソフトウェアをインストールしておく。Dockerのオーバーレイネットワーク機能を使うので、それを利用できるバージョンを入れる。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;docker (1.9以上)&lt;/li&gt;
&lt;li&gt;docker-compose (1.5以上)&lt;/li&gt;
&lt;li&gt;docker-machine&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;digitaloceanの登録とアクセストークンの取得:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;DigitalOceanの登録とアクセストークンの取得&lt;/h4&gt;

&lt;p&gt;登録後、管理画面からdocker-machineとの連携に必要なアクセストークンを発行できる。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;https://www.digitalocean.com/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;気をつけたいポイント４つ:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;気をつけたいポイント４つ&lt;/h3&gt;

&lt;h4 id=&#34;01-ホストosはkernel3-16以上のものを使う:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;01. ホストOSはKernel3.16以上のものを使う&lt;/h4&gt;

&lt;p&gt;例えば、ホストOSにUbuntu14.04を選んでいると、オーバーレイ・ネットワーク上にのコンテナを立ち上げる時にエラーが出る。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-compose up -d -x-networking

Creating network &amp;quot;xxx&amp;quot; with driver &amp;quot;overlay&amp;quot;
Creating yyy
ERROR: Cannot start container (container_id):
  subnet sandbox join failed for &amp;quot;10.0.0.0/24&amp;quot;:
  vxlan interface creation failed for
  subnet &amp;quot;10.0.0.0/24&amp;quot;: failed in prefunc:
  failed to set namespace on link &amp;quot;vxlanf9ac2ad&amp;quot;: invalid argument
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/get-started-overlay/&#34;&gt;Get started with multi-host networking&lt;/a&gt;によると、「A host with a 3.16 kernel version or higher.」とのこと。DigitalOceanのUbuntu14.04はカーネルが古いようなので、14.10とか15.04以上を使う必要がある。&lt;/p&gt;

&lt;h4 id=&#34;02-cluster-advertiseはeth0にするか-privatenetworkを有効にする:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;02. cluster-advertiseはeth0にするか、PrivateNetworkを有効にする&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/get-started-overlay/&#34;&gt;Get started with multi-host networking&lt;/a&gt;のサンプルをそのまま使うと、&lt;code&gt;docker-machine create&lt;/code&gt;時に概ね次のようなエラーに遭遇する。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create \
  ...
  --engine-opt &amp;quot;cluster-advertise=eth1:2376&amp;quot; \
  ...

Error creating machine: Error running provisioning:
Unable to verify the Docker daemon is listening: Maximum number of retries (10) exceeded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;現状、DigitalOceanの&lt;code&gt;eth1&lt;/code&gt;はプライベートネットワークのインタフェースで、デフォルト設定では、プライベートネットワークにIPが割り当てられない。&lt;/p&gt;

&lt;p&gt;なので、公開ネットワークの&lt;code&gt;eth0&lt;/code&gt;を使うか、&lt;code&gt;docker-machine create&lt;/code&gt;時に、全てのノードに&lt;code&gt;--digitalocean-private-networking&lt;/code&gt;をつけて、プライベートネットワークを有効にする。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-machine create
  ...
  --engine-opt &amp;quot;cluster-advertise=eth0:2376&amp;quot; \
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;docker-machine create
  ...
  --engine-opt &amp;quot;cluster-advertise=eth1:2376&amp;quot; \
  --digitalocean-private-networking \
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;03-consulはswarmクラスタ上に置いて節約する:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;03. ConsulはSwarmクラスタ上に置いて節約する&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/get-started-overlay/&#34;&gt;公式ドキュメント&lt;/a&gt;のサンプルでは、Consulキーストアで専用のホストを用意しているが、安いとはいえ、DigitalOceanでConsulキーストア専用にもつのは守銭奴らしからぬので、Swarmクラスタのノードに含めてしまおう。&lt;/p&gt;

&lt;p&gt;Swarmクラスタのノードを作成するときに、ConsulのURLを指定する場所があるが、作成時にはConsulキーストアが存在しなくても、Swarmが後々定期的にキーストアを更新してくれるようなので、割りと気にせずにノード構築後にConsulを導入できる。&lt;/p&gt;

&lt;p&gt;ただ、サンプルのように、ConsulをDockerコンテナで導入してしまうと、&lt;code&gt;docker ps&lt;/code&gt;時に、いつもリストに出てきてしまうので、気になる方はDocker上ではなく、ホストに直接インストールしてしまったほうが良い。(バイナリファイル１つだし)&lt;/p&gt;

&lt;p&gt;あと、Consulらしく全ノードに設置して、ヘルスチェックなどが出来ると良さそう。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.namiking.net/images/post/2016/01/docker-swarm-digitalocean/structure.svg&#34; alt=&#34;Docker Swarm + DigitalOcean&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;04-consulはプライベートネットワークに置く:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;04. Consulはプライベートネットワークに置く&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/networking/get-started-overlay/&#34;&gt;公式ドキュメント&lt;/a&gt;の感覚で、DigitalOceanにConsulキーストアを導入すると、グローバルにWebUIが公開されてしまい、精神的によろしくない。&lt;/p&gt;

&lt;p&gt;DigitalOceanには、一応プライベートネットワーク機能が用意されていて、管理画面やdocker-machineの引数から有効にできる。Consulはプライベートネットワーク側(eth1)のIPをバインドするとよい。&lt;/p&gt;

&lt;p&gt;プライベートネットワークにConsulを置くと、WebUIなどはグローバルIPから確認できなくなる。ブラウザからWebUIを確認したくなった場合は、SSHトンネルを利用して、8500ポートをフォワーディングしてやると楽。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ssh root@(マシンIP) \
  -i ~/.docker/machine/machines/(マシンID)/id_rsa \
  -L8500:localhost:8500

# ブラウザから開く
open http://localhost:8500
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;&lt;br /&gt;
プライベートネットワークといっても、
リージョンごとのネットワークのようなので、
あまり過信しないほうがよいみたい。&lt;/p&gt;

&lt;p&gt;使う前に知りたかったDigitalOceanまとめ
&lt;a href=&#34;http://pocketstudio.jp/log3/2015/04/13/digitalocean_introduction/&#34;&gt;http://pocketstudio.jp/log3/2015/04/13/digitalocean_introduction/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;具体的な実行手順:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;具体的な実行手順&lt;/h3&gt;

&lt;p&gt;自動化しやすいように、上のポイント４つを踏まえたシェルの実行手順を以下にまとめる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# マスターノード作成
docker-machine create \
  --driver digitalocean \
  --digitalocean-access-token ${DIGITALOCEAN_TOKEN} \
  --digitalocean-image &amp;quot;ubuntu-15-10-x64&amp;quot; \
  --digitalocean-region &amp;quot;sgp1&amp;quot; \
  --digitalocean-size &amp;quot;512mb&amp;quot; \
  --digitalocean-private-networking \
  --swarm --swarm-master \
  --swarm-discovery \
    &amp;quot;consul://localhost:8500&amp;quot; \
  --engine-opt \
    &amp;quot;cluster-store=consul://localhost:8500&amp;quot; \
  --engine-opt &amp;quot;cluster-advertise=eth1:2376&amp;quot; \
  swarm-node0

# マスターノードにConsulを設置
docker-machine ssh swarm-node0 &amp;quot;
  apt-get install -y at zip &amp;amp;&amp;amp;\
  cd /tmp &amp;amp;&amp;amp;\
  curl -LO https://releases.hashicorp.com/consul/0.6.1/consul_0.6.1_linux_amd64.zip &amp;amp;&amp;amp;\
  unzip consul_0.6.1_linux_amd64.zip &amp;amp;&amp;amp;\
  mv consul /usr/local/bin &amp;amp;&amp;amp;\
  curl -LO https://releases.hashicorp.com/consul/0.6.1/consul_0.6.1_web_ui.zip &amp;amp;&amp;amp;\
  unzip consul_0.6.1_web_ui.zip -d consul-webui &amp;amp;&amp;amp;\
  echo \&amp;quot;
    consul agent \
      -server -bootstrap-expect=1 \
      -node=consul00 \
      -data-dir=/tmp/consul \
      --ui-dir=/tmp/consul-webui \
      -bind=\$(
        ip addr show eth1 \
        | grep -o -e &#39;[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+&#39; \
        | head -n1
      ) \
    &amp;gt;&amp;gt; /var/log/consul.log
  \&amp;quot; | at now
&amp;quot;

# マスターのプライベートIPを取得
MASTER_PRIVATE_IP=$(
  docker-machine ssh swarm-node0 &amp;quot;
    ip addr show eth1 \
    | grep -o -e &#39;[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+&#39; \
    | head -n1
  &amp;quot;
)

# ノード作成
docker-machine create \
  --driver digitalocean \
  --digitalocean-access-token ${DIGITALOCEAN_TOKEN} \
  --digitalocean-image &amp;quot;ubuntu-15-10-x64&amp;quot; \
  --digitalocean-region &amp;quot;sgp1&amp;quot; \
  --digitalocean-size &amp;quot;512mb&amp;quot; \
  --digitalocean-private-networking \
  --swarm \
  --swarm-discovery \
    &amp;quot;consul://localhost:8500&amp;quot; \
  --engine-opt \
    &amp;quot;cluster-store=consul://localhost:8500&amp;quot; \
  --engine-opt &amp;quot;cluster-advertise=eth1:2376&amp;quot; \
  swarm-node1

# ノードにConsulを設置
docker-machine ssh swarm-node1 &amp;quot;
  apt-get install -y at zip &amp;amp;&amp;amp;\
  cd /tmp &amp;amp;&amp;amp;\
  curl -LO https://releases.hashicorp.com/consul/0.6.1/consul_0.6.1_linux_amd64.zip &amp;amp;&amp;amp;\
  unzip consul_0.6.1_linux_amd64.zip &amp;amp;&amp;amp;\
  mv consul /usr/local/bin &amp;amp;&amp;amp;\
  echo \&amp;quot;
    consul agent \
      -join=$MASTER_PRIVATE_IP \
      -node=consul01 \
      -data-dir=/tmp/consul \
      -bind=\$(
        ip addr show eth1 \
        | grep -o -e &#39;[0-9]\+\.[0-9]\+\.[0-9]\+\.[0-9]\+&#39; \
        | head -n1
      ) \
    &amp;gt;&amp;gt; /var/log/consul.log
  \&amp;quot; | at now
&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;注記いくつか:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;注記いくつか&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;シェル中の&lt;code&gt;${DIGITALOCEAN_TOKEN}&lt;/code&gt;はDigitalOceanの管理画面から取得したアクセストークンに置き換える。&lt;/li&gt;
&lt;li&gt;Consul起動に&lt;code&gt;at now&lt;/code&gt;コマンドを使っているのは、&lt;code&gt;nohup&lt;/code&gt;や&lt;code&gt;&amp;amp;&lt;/code&gt;を使っても、Consulがフォアグラウンドで走ってしまい、バッチ処理が途中で止まってしまうため。&lt;code&gt;docker-machine ssh&lt;/code&gt;の仕様の問題？&lt;/li&gt;
&lt;li&gt;Consul実行時にbindに指定しているのは、自身のプライベートIP。&lt;/li&gt;
&lt;li&gt;途中で、マスターのプライベートIPを取得しているのは、各ノードに設置したConsulクライアントをサーバーにJOINさせるため。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;動作確認:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;動作確認&lt;/h3&gt;

&lt;h4 id=&#34;swarmクラスタ確認:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;Swarmクラスタ確認&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ eval $(docker-machine env --swarm swarm-node0)
$ docker info

Containers: 3
Images: 2
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 2
 swarm-node0: x.x.x.x:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 513.4 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.2.0-16-generic, operatingsystem=Ubuntu 15.10, provider=digitalocean, storagedriver=aufs
 swarm-node1: y.y.y.y:2376
  └ Status: Healthy
  └ Containers: 1
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 513.4 MiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.2.0-16-generic, operatingsystem=Ubuntu 15.10, provider=digitalocean, storagedriver=aufs
CPUs: 2
Total Memory: 1.003 GiB
Name: swarm-node0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ノードが２つあることが確認できる。&lt;/p&gt;

&lt;h4 id=&#34;オーバーレイ-ネットワークの確認:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;オーバーレイ・ネットワークの確認&lt;/h4&gt;

&lt;h5 id=&#34;docker-compose-yml:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;docker-compose.yml&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-ruby&#34;&gt;container1:
  image: busybox
  container_name: container1
  environment:
    - constraint:node==/node0/
  command: tail -f /dev/null

container2:
  image: busybox
  container_name: container2
  environment:
    - constraint:node==/node1/
  command: tail -f /dev/null
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;ネットワークモードでコンテナを立ち上げる:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;ネットワークモードでコンテナを立ち上げる&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker-compose --x-networking up -d
$ docker ps --format &amp;quot;{{.Names}}&amp;quot;

swarm-node0/container1
swarm-node1/container2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;それぞれのノードにコンテナが作られた。&lt;/p&gt;

&lt;h5 id=&#34;疎通確認:fa799c0a70e6a2da19a2eb6d62e423f4&#34;&gt;疎通確認&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker exec -it container1 ping container2 -c4

PING container2 (10.0.0.3): 56 data bytes
64 bytes from 10.0.0.3: seq=0 ttl=64 time=1.470 ms
64 bytes from 10.0.0.3: seq=1 ttl=64 time=0.691 ms
64 bytes from 10.0.0.3: seq=2 ttl=64 time=0.620 ms
64 bytes from 10.0.0.3: seq=3 ttl=64 time=0.699 ms

--- container2 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.620/0.870/1.470 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ docker exec -it container2 ping container1 -c4

PING container1 (10.0.0.2): 56 data bytes
64 bytes from 10.0.0.2: seq=0 ttl=64 time=1.379 ms
64 bytes from 10.0.0.2: seq=1 ttl=64 time=0.854 ms
64 bytes from 10.0.0.2: seq=2 ttl=64 time=0.847 ms
64 bytes from 10.0.0.2: seq=3 ttl=64 time=0.861 ms

--- container1 ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.847/0.985/1.379 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;オーバーレイ・ネットワークの疎通も問題なさそう。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>